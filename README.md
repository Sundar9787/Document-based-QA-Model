# Document-based Question Answering using RAG

## ğŸ“Œ Overview
This project implements a **Retrieval-Augmented Generation (RAG)** pipeline to answer user queries based on custom document datasets.  
The system combines **semantic search** with **generative AI models** to produce context-aware and accurate answers.

## ğŸš€ Features
- **Document Preprocessing** â€“ Cleans and processes raw documents.
- **Text Chunking** â€“ Splits large documents into manageable chunks for better retrieval.
- **Vector Embeddings** â€“ Uses transformer-based models to convert text into dense vectors.
- **Semantic Search** â€“ Retrieves the most relevant document chunks using a vector database.
- **Answer Generation** â€“ Uses Googleâ€™s Gemini 1.5 Flash model for generating accurate responses.
- **RAG Architecture** â€“ Combines retrieval and generation for improved QA performance.

## ğŸ› ï¸ Tech Stack
- **Python 3.10+**
- **Transformers** (Hugging Face)
- **SentenceTransformers**
- **Google Generative AI SDK**
- **FAISS** (for vector storage & retrieval)
- **Pandas, NumPy**
  

```

## âš™ï¸ How It Works
1. **Document Ingestion** â€“ Load and preprocess documents (PDF, TXT, DOCX, etc.).
2. **Text Chunking** â€“ Break documents into smaller, overlapping segments.
3. **Embedding Generation** â€“ Convert chunks into vector embeddings.
4. **Vector Storage** â€“ Store embeddings in a vector database for quick retrieval.
5. **Query Handling** â€“ Convert the userâ€™s question into an embedding.
6. **Relevant Context Retrieval** â€“ Find top-N chunks most relevant to the query.
7. **Answer Generation** â€“ Pass the retrieved context + query to a generative model.
8. **Output** â€“ Display a final, contextually accurate answer.

## ğŸ“Š Example
**Query:** *"What are the key features of the project?"*  
**Answer:** *"The project uses a Retrieval-Augmented Generation architecture with semantic search, text chunking, and generative AI to answer document-based queries accurately."*

## ğŸ“ˆ Results
- Improved **accuracy** and **context relevance** compared to keyword-based search.
- Handles **long documents** efficiently with chunking and semantic embeddings.
- Provides **human-like responses** with minimal hallucination.

## â–¶ï¸ Installation & Usage
```bash
# Clone repository
git clone (https://github.com/Sundar9787/Document-based-QA-Model.git)
cd Document-based-QA-Model

# Install dependencies
pip install -r requirements.txt

# Run application
streamlit run app.py
```

